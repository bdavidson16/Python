{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Coursera IBM Data Engineering: *Python Project for Data Engineering*\n",
        "## Project & Scenario:\n",
        "Create a code that can be used to:\n",
        "1. **Extract** - compile the list of the top 10 largest banks in the world ranked by market capitalization in billion USD\n",
        "2. **Transform** - the data needs to be transformed and stored in GBP, EUR and INR as well, in accordance with the exchange rate information that has been made available to you as a CSV file.\n",
        "3. **Load** - the processed information table is to be saved locally in a CSV format and as a database table.\n",
        "\n",
        "We need to use the following information to complete this project:\n",
        "\n",
        "| Parameter\t| Value |\n",
        "------------|---------|\n",
        "| Code name\t| banks_project.py |\n",
        "| Data URL\t| https://web.archive.org/web/20230908091635 /https://en.wikipedia.org/wiki/List_of_largest_banks|\n",
        "| Exchange rate CSV path | \thttps://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv|\n",
        "| Table Attributes (upon Extraction only)\t| Name, MC_USD_Billion|\n",
        "| Table Attributes (final)\t| Name, MC_USD_Billion, MC_GBP_Billion, MC_EUR_Billion, MC_INR_Billion|\n",
        "| Output CSV Path\t| ./Largest_banks_data.csv|\n",
        "| Database name\t| Banks.db|\n",
        "| Table name\t| Largest_banks|\n",
        "| Log file\t| code_log.txt|\n",
        "\n",
        "\n",
        "### **Project tasks**\n",
        "\n",
        "Task 1:\n",
        "Write a function log_progress() to log the progress of the code at different stages in a file code_log.txt. Use the list of log points provided to create log entries as every stage of the code.\n",
        "\n",
        "Task 2:\n",
        "**Extract** the tabular information from the given URL under the heading 'By market capitalization' and save it to a dataframe.\n",
        "\n",
        "1. *Inspect* the webpage and identify the position and pattern of the tabular information in the HTML code\n",
        "2. *Write* the code for a function extract() to perform the required data extraction.\n",
        "3. *Execute* a function call to extract() to verify the output.\n",
        "\n",
        "Task 3:\n",
        "**Transform** the dataframe by adding columns for Market Capitalization in GBP, EUR and INR, rounded to 2 decimal places, based on the exchange rate information shared as a CSV file.\n",
        "\n",
        "1. *Write* the code for a function transform() to perform the said task.\n",
        "2. *Execute* a function call to transform() and verify the output.\n",
        "\n",
        "Task 4:\n",
        "**Load** the transformed dataframe to an output *CSV file*. Write a function load_to_csv(), execute a function call and verify the output.\n",
        "\n",
        "Task 5:\n",
        "**Load** the transformed dataframe to an *SQL database server* as a table. Write a function load_to_db(), execute a function call and verify the output.\n",
        "\n",
        "Task 6:\n",
        "Run queries on the database table. Write a function load_to_db(), execute a given set of queries and verify the output.\n",
        "\n",
        "Task 7:\n",
        "Verify that the log entries have been completed at all stages by checking the contents of the file code_log.txt."
      ],
      "metadata": {
        "id": "D4cmrpbfE2Jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries imported for use\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import csv\n",
        "import sqlite3\n",
        "from sqlalchemy import create_engine, MetaData, Table, Column, String, Float, text, select\n",
        "from sqlalchemy.exc import OperationalError\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from sqlalchemy.ext.declarative import declarative_base"
      ],
      "metadata": {
        "id": "tytLDEjJC1kx"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Create Text File\n",
        "I need to create a text file to save all of my data to while working.\n"
      ],
      "metadata": {
        "id": "XzE-pcqMKqYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open new txt file\n",
        "file = open(\"code_log.txt\", \"w\")\n",
        "\n",
        "# define function to write to file\n",
        "def log_progress(string):\n",
        "  file.write(string + '\\n')\n"
      ],
      "metadata": {
        "id": "PeC7lwZqK_A-"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Extract\n",
        "I need to extract information from both the URL and CSV file provided.\n",
        "\n",
        "From the URL:\n",
        "- I need to find the table that I need information from\n",
        "- Then, I will store this information into a list to later make computations\n",
        "\n",
        "From the CSV file:\n",
        "- I need to simply put it into a dataframe"
      ],
      "metadata": {
        "id": "J1xejd5XLdcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# extract and save CSV info into dataframe 1\n",
        "def extract_csv(file):\n",
        "    dataframe = pd.read_csv(file)\n",
        "    return dataframe\n",
        "\n",
        "df = extract_csv('/content/exchange_rate.csv')\n",
        "print(df)\n",
        "\n",
        "log_progress('CSV file extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pSWW_I2C4w_",
        "outputId": "f4d29740-55f2-4d2c-99a3-7f8884daf4eb",
        "collapsed": true
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Currency   Rate\n",
            "0      EUR   0.93\n",
            "1      GBP   0.80\n",
            "2      INR  82.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# extract from web page and save into dataframe 2\n",
        "# df2 -> (which will be the one we will save and export as a CSV later)\n",
        "# request url and format with html parser\n",
        "url_mc = requests.get('https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks')\n",
        "data_mc = BeautifulSoup(url_mc.content, 'html.parser')\n",
        "\n",
        "#find table that I want\n",
        "table = data_mc.find('table', {'class':'wikitable'})\n",
        "\n",
        "# define headers\n",
        "headers = [header.text.strip() for header in table.find_all('th')]\n",
        "\n",
        "#create list\n",
        "data = []\n",
        "\n",
        "# loop through table and output results\n",
        "rows = table.find_all('tr')\n",
        "for row in rows[1:]:\n",
        "    columns = row.find_all('td')\n",
        "    if len(columns) > 0:\n",
        "        row_data = [col.text.strip() for col in columns]\n",
        "        data.append(row_data)\n",
        "\n",
        "# write results in top_banks_df\n",
        "top_banks_df = pd.DataFrame(data, columns=headers)\n",
        "\n",
        "print(top_banks_df)\n",
        "\n",
        "log_progress('Webpage extracted and added to top_banks_df')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGMqwAVA5Nzu",
        "outputId": "0d0562e7-2fcf-4f99-b436-6945956847ae"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Rank                                Bank name Market cap(US$ billion)\n",
            "0    1                           JPMorgan Chase                  432.92\n",
            "1    2                          Bank of America                  231.52\n",
            "2    3  Industrial and Commercial Bank of China                  194.56\n",
            "3    4               Agricultural Bank of China                  160.68\n",
            "4    5                                HDFC Bank                  157.91\n",
            "5    6                              Wells Fargo                  155.87\n",
            "6    7                        HSBC Holdings PLC                  148.90\n",
            "7    8                           Morgan Stanley                  140.83\n",
            "8    9                  China Construction Bank                  139.82\n",
            "9   10                            Bank of China                  136.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Transform\n",
        "Now we need to transform the data:\n",
        "\n",
        "1. They want us to use the column names \"Name\" and \"MC_USD_Billion\", so we will first change those before more analysis.\n",
        "\n",
        "2. Then, they want us to use the exchange rate from df/csv file to show the Market cap in GBP, EUR, and INR currency rather than just USD. We will multiple the Market cap in top_banks_df by the rate in df/csv."
      ],
      "metadata": {
        "id": "1vwXsG4vbASv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# update column names\n",
        "top_banks_df.columns = ['Rank', 'Name', 'MC_USD_Billion']\n",
        "print(top_banks_df)\n",
        "\n",
        "log_progress('Updated column names and drop Rank column')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yFnQ_x5dDst",
        "outputId": "4d4a1d5e-2ff6-4324-da61-8bc3c9f4459b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Rank                                     Name MC_USD_Billion\n",
            "0    1                           JPMorgan Chase         432.92\n",
            "1    2                          Bank of America         231.52\n",
            "2    3  Industrial and Commercial Bank of China         194.56\n",
            "3    4               Agricultural Bank of China         160.68\n",
            "4    5                                HDFC Bank         157.91\n",
            "5    6                              Wells Fargo         155.87\n",
            "6    7                        HSBC Holdings PLC         148.90\n",
            "7    8                           Morgan Stanley         140.83\n",
            "8    9                  China Construction Bank         139.82\n",
            "9   10                            Bank of China         136.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transform and create columns\n",
        "# make sure that all columns to calculate are numeric\n",
        "top_banks_df['MC_USD_Billion'] = pd.to_numeric(top_banks_df['MC_USD_Billion'], errors='coerce')\n",
        "\n",
        "# create variables for currency rates\n",
        "EUR_rate = df.loc[df['Currency'] =='EUR', ['Rate']].values[0]\n",
        "GBP_rate = df.loc[df['Currency'] =='GBP', ['Rate']].values[0]\n",
        "INR_rate = df.loc[df['Currency'] =='INR', ['Rate']].values[0]\n",
        "\n",
        "# define transform to calculate translate currency columns\n",
        "def transform(column, currency_name):\n",
        "    top_banks_df[f'MC_{currency_name}_Billion'] = np.round(top_banks_df['MC_USD_Billion'] * column, 2)\n",
        "\n",
        "# pass currency rates\n",
        "transform(EUR_rate, 'EUR')\n",
        "transform(GBP_rate, 'GBP')\n",
        "transform(INR_rate, 'INR')\n",
        "\n",
        "# print new dataframe\n",
        "print(top_banks_df)\n",
        "\n",
        "log_progress('Transformed data in top_banks_df')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j9Nfp-EdkIz",
        "outputId": "543f6dc2-f5f5-4361-bfd5-07ab1a2a8e2a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Rank                                     Name  MC_USD_Billion  \\\n",
            "0    1                           JPMorgan Chase          432.92   \n",
            "1    2                          Bank of America          231.52   \n",
            "2    3  Industrial and Commercial Bank of China          194.56   \n",
            "3    4               Agricultural Bank of China          160.68   \n",
            "4    5                                HDFC Bank          157.91   \n",
            "5    6                              Wells Fargo          155.87   \n",
            "6    7                        HSBC Holdings PLC          148.90   \n",
            "7    8                           Morgan Stanley          140.83   \n",
            "8    9                  China Construction Bank          139.82   \n",
            "9   10                            Bank of China          136.81   \n",
            "\n",
            "   MC_EUR_Billion  MC_GBP_Billion  MC_INR_Billion  \n",
            "0          402.62          346.34        35910.71  \n",
            "1          215.31          185.22        19204.58  \n",
            "2          180.94          155.65        16138.75  \n",
            "3          149.43          128.54        13328.41  \n",
            "4          146.86          126.33        13098.63  \n",
            "5          144.96          124.70        12929.42  \n",
            "6          138.48          119.12        12351.26  \n",
            "7          130.97          112.66        11681.85  \n",
            "8          130.03          111.86        11598.07  \n",
            "9          127.23          109.45        11348.39  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4: Export to CSV file."
      ],
      "metadata": {
        "id": "NjsY2JlbEsmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_to_csv(csvfile):\n",
        "    top_banks_df.to_csv(csvfile, index=False)\n",
        "\n",
        "load_to_csv('./Largest_banks_data.csv');\n",
        "new_df = pd.read_csv('./Largest_banks_data.csv')\n",
        "print(new_df)\n",
        "\n",
        "log_progress('CSV file exported using top_banks_df')"
      ],
      "metadata": {
        "id": "4UdeJ7e5EiDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62bbea8c-55f1-4bf7-d51f-6a211cc4160a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Rank                                     Name  MC_USD_Billion  \\\n",
            "0     1                           JPMorgan Chase          432.92   \n",
            "1     2                          Bank of America          231.52   \n",
            "2     3  Industrial and Commercial Bank of China          194.56   \n",
            "3     4               Agricultural Bank of China          160.68   \n",
            "4     5                                HDFC Bank          157.91   \n",
            "5     6                              Wells Fargo          155.87   \n",
            "6     7                        HSBC Holdings PLC          148.90   \n",
            "7     8                           Morgan Stanley          140.83   \n",
            "8     9                  China Construction Bank          139.82   \n",
            "9    10                            Bank of China          136.81   \n",
            "\n",
            "   MC_EUR_Billion  MC_GBP_Billion  MC_INR_Billion  \n",
            "0          402.62          346.34        35910.71  \n",
            "1          215.31          185.22        19204.58  \n",
            "2          180.94          155.65        16138.75  \n",
            "3          149.43          128.54        13328.41  \n",
            "4          146.86          126.33        13098.63  \n",
            "5          144.96          124.70        12929.42  \n",
            "6          138.48          119.12        12351.26  \n",
            "7          130.97          112.66        11681.85  \n",
            "8          130.03          111.86        11598.07  \n",
            "9          127.23          109.45        11348.39  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5/6: Load to Database & Run Queries"
      ],
      "metadata": {
        "id": "-dNoB5_bE8a7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "9DKn2vid4lIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f7836c4-cb4c-48fe-95d9-8f2a99999668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching all records:\n",
            "('JPMorgan Chase', 432.92, 346.34, 402.62, 35910.71)\n",
            "('Bank of America', 231.52, 185.22, 215.31, 19204.58)\n",
            "('Industrial and Commercial Bank of China', 194.56, 155.65, 180.94, 16138.75)\n",
            "('Agricultural Bank of China', 160.68, 128.54, 149.43, 13328.41)\n",
            "('HDFC Bank', 157.91, 126.33, 146.86, 13098.63)\n",
            "('Wells Fargo', 155.87, 124.7, 144.96, 12929.42)\n",
            "('HSBC Holdings PLC', 148.9, 119.12, 138.48, 12351.26)\n",
            "('Morgan Stanley', 140.83, 112.66, 130.97, 11681.85)\n",
            "('China Construction Bank', 139.82, 111.86, 130.03, 11598.07)\n",
            "('Bank of China', 136.81, 109.45, 127.23, 11348.39)\n",
            "\n",
            "\n",
            "[('JPMorgan Chase', 346.34), ('Bank of America', 185.22), ('Industrial and Commercial Bank of China', 155.65), ('Agricultural Bank of China', 128.54), ('HDFC Bank', 126.33), ('Wells Fargo', 124.7), ('HSBC Holdings PLC', 119.12), ('Morgan Stanley', 112.66), ('China Construction Bank', 111.86), ('Bank of China', 109.45)]\n",
            "\n",
            "\n",
            "[('JPMorgan Chase', 402.62), ('Bank of America', 215.31), ('Industrial and Commercial Bank of China', 180.94), ('Agricultural Bank of China', 149.43), ('HDFC Bank', 146.86), ('Wells Fargo', 144.96), ('HSBC Holdings PLC', 138.48), ('Morgan Stanley', 130.97), ('China Construction Bank', 130.03), ('Bank of China', 127.23)]\n",
            "\n",
            "\n",
            "[('JPMorgan Chase', 35910.71), ('Bank of America', 19204.58), ('Industrial and Commercial Bank of China', 16138.75), ('Agricultural Bank of China', 13328.41), ('HDFC Bank', 13098.63), ('Wells Fargo', 12929.42), ('HSBC Holdings PLC', 12351.26), ('Morgan Stanley', 11681.85), ('China Construction Bank', 11598.07), ('Bank of China', 11348.39)]\n"
          ]
        }
      ],
      "source": [
        "# connect to server and load new CSV file\n",
        "def load_to_db(dataframe):\n",
        "    # create database and assign metadata\n",
        "    engine = create_engine('sqlite:///Banks.db')\n",
        "    metadata = MetaData()\n",
        "\n",
        "    # create table and schema\n",
        "    largest_banks = Table(\n",
        "        'Largest_banks',\n",
        "        metadata,\n",
        "        Column('Name', String, primary_key=True),\n",
        "        Column('MC_USD_Billion', Float),\n",
        "        Column('MC_GBP_Billion', Float),\n",
        "        Column('MC_EUR_Billion', Float),\n",
        "        Column('MC_INR_Billion', Float)\n",
        "    )\n",
        "\n",
        "    # Execute queries\n",
        "    with engine.connect() as connection:\n",
        "        # Convert the DataFrame to SQL\n",
        "        dataframe.to_sql('Largest_banks', con=engine, if_exists='replace', index=False)\n",
        "\n",
        "        # Query the database\n",
        "        print(\"Fetching all records:\")\n",
        "        stmt = select(largest_banks)\n",
        "        result = connection.execute(stmt)\n",
        "        for row in result:\n",
        "            print(row)\n",
        "\n",
        "        # select banks in table with only GBP Market Capilatization conversion\n",
        "        london_query = text(\"SELECT Name, MC_GBP_Billion FROM Largest_banks\")\n",
        "        result = connection.execute(london_query)\n",
        "        print(\"\\n\")\n",
        "        print(result.fetchall())\n",
        "\n",
        "        # select banks in table with only EUR Market Capilatization conversion\n",
        "        berlin_query = text(\"SELECT Name, MC_EUR_Billion FROM Largest_banks\")\n",
        "        result = connection.execute(berlin_query)\n",
        "        print(\"\\n\")\n",
        "        print(result.fetchall())\n",
        "\n",
        "        # select banks in table with only INR Market Capilatization conversion\n",
        "        delhi_query = text(\"SELECT Name, MC_INR_Billion FROM Largest_banks\")\n",
        "        result = connection.execute(delhi_query)\n",
        "        print(\"\\n\")\n",
        "        print(result.fetchall())\n",
        "\n",
        "# run new_df through function\n",
        "load_to_db(new_df)\n",
        "\n",
        "log_progress('Database loaded and queries executed')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 7: Close File and Check Log"
      ],
      "metadata": {
        "id": "e-j5NHa_IEw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# close file and print file to double check code progress was loggeds\n",
        "file.close()\n",
        "\n",
        "with open(\"./code_log.txt\", \"r\") as file:\n",
        "    content = file.read()\n",
        "    print(content)\n"
      ],
      "metadata": {
        "id": "yahExn5buxTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d59090-eac1-44ec-f920-e406e7ac253d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file extracted\n",
            "Webpage extracted and added to top_banks_df\n",
            "Updated column names and drop Rank column\n",
            "Transformed data in top_banks_df\n",
            "CSV file exported using top_banks_df\n",
            "Database loaded and queries executed\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Credit/Info:\n",
        "\n",
        "*Student/Author*: Bailey Davidson\n",
        "\n",
        "January 3rd, 2025"
      ],
      "metadata": {
        "id": "qWLAy52IH07H"
      }
    }
  ]
}